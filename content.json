[{"title":"Tomcat学习（二）","date":"2020-01-04T06:03:25.000Z","path":"2020/01/04/Tomcat学习（二）/","text":"概要 Connector组成 Connector分类 Connector组成 ProtocolHandler创建对应Endpoint,用来处理请求。 Adapter是Connector与Container容器之间的一个连接器。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Connector extends LifecycleMBeanBase &#123; // 协议Handler protected final ProtocolHandler protocolHandler; // Coyote adapter. protected Adapter adapter = null; public Connector() &#123; // 默认使用nio this(\"org.apache.coyote.http11.Http11NioProtocol\"); &#125; public Connector(String protocol) &#123; // 传入协议名称 boolean aprConnector = AprLifecycleListener.isAprAvailable() &amp;&amp; AprLifecycleListener.getUseAprConnector(); // 是否开启Apr if (\"HTTP/1.1\".equals(protocol) || protocol == null) &#123; // HTTP/1.1 if (aprConnector) &#123; protocolHandlerClassName = \"org.apache.coyote.http11.Http11AprProtocol\"; &#125; else &#123; protocolHandlerClassName = \"org.apache.coyote.http11.Http11NioProtocol\"; &#125; &#125; else if (\"AJP/1.3\".equals(protocol)) &#123; // AJP/1.3 if (aprConnector) &#123; protocolHandlerClassName = \"org.apache.coyote.ajp.AjpAprProtocol\"; &#125; else &#123; protocolHandlerClassName = \"org.apache.coyote.ajp.AjpNioProtocol\"; &#125; &#125; else &#123; protocolHandlerClassName = protocol; // 其他自定义协议实现 &#125; ProtocolHandler p = null; try &#123; // 反射获取协议处理类 Class&lt;?&gt; clazz = Class.forName(protocolHandlerClassName); // 实例化 p = (ProtocolHandler) clazz.getConstructor().newInstance(); &#125; catch (Exception e) &#123; log.error(sm.getString( \"coyoteConnector.protocolHandlerInstantiationFailed\"), e); &#125; finally &#123; this.protocolHandler = p; &#125; ... &#125;&#125; Connector分类可以分为以下三类 Http Connector：解析HTTP请求，又分为BIO Http Connector和NIO Http Connector，即阻塞IO Connector和非阻塞IO Connector。本文主要分析NIO Http Connector的实现过程。 AJP Connector：基于AJP协议，用于Tomcat与HTTP服务器通信定制的协议，能提供较高的通信速度和效率。如与Apache服务器集成时，采用这个协议。 APR HTTP Connector：用C实现，通过JNI调用的。主要提升对静态资源（如HTML、图片、CSS、JS等）的访问性能。 具体要使用哪种Connector可以在server.xml文件中通过protocol属性配置如下： 123&lt;Connector port=\"8080\" protocol=\"org.apache.coyote.http11.Http11AprProtocol\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt; 每一类Connector对应这一种protocolHandler，protocolHandler用来监听服务器某个端口的请求，但并不处理(处理请求由容器组件完成)。 以Http11NioProtocol为例分析启动初始化过程： 在Connector的startInternal()方法中启动了protocolHandler,代码如下： 1234567891011121314protected void startInternal() throws LifecycleException &#123; if (getPortWithOffset() &lt; 0) &#123; throw new LifecycleException(sm.getString( \"coyoteConnector.invalidPort\", Integer.valueOf(getPortWithOffset()))); &#125; setState(LifecycleState.STARTING); try &#123; //启动protocolHandler protocolHandler.start(); &#125; catch (Exception e) &#123; throw new LifecycleException( sm.getString(\"coyoteConnector.protocolHandlerStartFailed\"), e); &#125;&#125; 在AbstractProtocol的start()方法中启动endpoint 123456789101112131415161718@Overridepublic void start() throws Exception &#123; if (getLog().isInfoEnabled()) &#123; getLog().info(sm.getString(\"abstractProtocolHandler.start\", getName())); logPortOffset(); &#125; //启动endpoint endpoint.start(); monitorFuture = getUtilityExecutor().scheduleWithFixedDelay( new Runnable() &#123; @Override public void run() &#123; if (!isPaused()) &#123; startAsyncTimeout(); &#125; &#125; &#125;, 0, 60, TimeUnit.SECONDS);&#125; 在NioEndpoint的startInternal()方法，创建creating acceptor, poller threads. 12345678910111213141516171819202122232425262728293031323334353637383940/** * Start the NIO endpoint, creating acceptor, poller threads. */@Overridepublic void startInternal() throws Exception &#123; if (!running) &#123; running = true; paused = false; if (socketProperties.getProcessorCache() != 0) &#123; processorCache = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE, socketProperties.getProcessorCache()); &#125; if (socketProperties.getEventCache() != 0) &#123; eventCache = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE, socketProperties.getEventCache()); &#125; if (socketProperties.getBufferPool() != 0) &#123; nioChannels = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE, socketProperties.getBufferPool()); &#125; // Create worker collection if (getExecutor() == null) &#123; createExecutor(); &#125; initializeConnectionLatch(); // Start poller thread poller = new Poller(); Thread pollerThread = new Thread(poller, getName() + \"-ClientPoller\"); pollerThread.setPriority(threadPriority); pollerThread.setDaemon(true); pollerThread.start(); startAcceptorThread(); &#125;&#125; Http11NioProtocol创建一个org.apache.tomcat.util.net.NioEndpoint实例,然后将监听端口并解析请求的工作全被委托给NioEndpoint实现。tomcat在使用Http11NioProtocol解析HTTP请求时一共设计了三种线程，分别为Acceptor，Poller和Worker。","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://www.qiudx.top/tags/tomcat/"}]},{"title":"Tomcat学习（一）","date":"2020-01-03T09:59:40.000Z","path":"2020/01/03/Tomcat学习（一）/","text":"概要 什么是tomcat? tomcat作用 Servlet由来？做什么的？ Servlet是如何工作的？ Tomcat的组成 什么是tomcat?Tomcat是Servlet的运行环境，可以称之为容器，Tomcat是运行在JVM上的应用服务器 tomcat作用 接受请求并解析请求 处理请求 返回响应 Servlet由来？做什么的？Servlet是SUN为了让Java能实现动态的可交互的网页,从而进入web编程的领域而定义的一套标准. 这套标准是这么说的: 你想用Java开发动态网页, 可以定义一个自己的”Servlet”,但一定要实现HTTPServlet接口,然后重载doGet(),doPost()方法.用户从流浪器GET的时候,调用doGet方法,从流浪器向服务器发送表单数据的时候,调用doPost方法,如果你想访问用户从浏览器传递过来的参数,用HttpServletRequest对象就好了,里面有getParameter,getQueryString方法,如果你处理完了,想向浏览器返回数据,用HttpServletResponse对象调用getPrintWriter方法就可以输出数据了. 如果你想实现一个购物车,需要session,很简单,从HttpServletRequest调用getSession方法就可以了. Servlet是如何工作的？ 由servlet容器创建一个实现ServletRequest或HttpServletRequest的实例，该request中包含请求类型，URL，协议，参数，Cookies等 由servlet容器创建一个实现ServletReponse或HttpServletReponse的实例，用来向Web客户端发送响应。 调用Servlet的service方法,将request对象和response对象作为参数传入。Servlet从request对象中读取信息,并通过response对象发送响应信息. Tomcat的组成 Server(服务器)和Service(服务) Connector(连接器) HTTP AJP(apache私有协议，用于tomcat和apache静态服务器通信) Container(容器) Engine Host Context Wrapper Component(组件) Manager（管理器） logger（日志管理） loader（载入器） pipeline(管道) valve（管道中的阀）","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"https://www.qiudx.top/tags/tomcat/"}]},{"title":"中国爬虫违法违规案例汇总","date":"2020-01-02T10:58:24.000Z","path":"2020/01/02/中国爬虫违法违规案例汇总/","text":"最近在 GitHub 发现了一个仓库，这个库整理了所有中国大陆爬虫开发者涉诉与违规相关的新闻、资料与法律法规 。 GitHub 地址： https://github.com/HiddenStrawberry/Crawler_Illegal_Cases_In_China 本项目用来整理所有中国大陆爬虫开发者涉诉与违规相关的新闻、资料与法律法规。致力于帮助在中国大陆工作的爬虫行业从业者了解我国相关法律，避免触碰数据合规红线。 违法违规案例汇总爬虫禁区1：为违法违规组织提供爬虫相关服务（验证码识别服务贩卖、SEO……） CASE1:知乎某极验破解者自述被抓（已删除） CASE2:“快啊答题”AI破解验证码服务开发者被判刑 CASE9:永嘉警方揪出“黑”百度黑客团伙 干扰搜索引擎牟利超七千万元 爬虫禁区2：个人隐私数据抓取与贩卖 CASE3:简历大数据公司“巧达科技”被一锅端 CASE4:社保掌上通被下架 用户的信息很容易泄露太不安全了 CASE5:爬虫为何受关注？业内：大数据服务商或因合作方涉套路贷犯罪而被牵连 爬虫禁区3：利用无版权的商业数据获利 CASE6:“车来了”涉嫌偷数据被警方立案 CASE8:裁判文书网数据竟被售卖：爬虫程序抓取 或成侵权 爬虫禁区4：？ CASE7:头疼大战前传：头条前高管反噬被判刑 相关法律法规介绍非法获取计算机系统数据罪 根据《中华人民共和国刑法》第二百八十五条规定，非法获取计算机信息系统数据、非法控制计算机信息系统罪，是指违反国家规定，侵入国家事务、国防建设、尖端科学技术领域以外的计算机信息系统或者采用其他技术手段，获取该计算机信息系统中存储、处理或者传输的数据，情节严重的行为。刑法第285条第2款明确规定，犯本罪的，处三年以下有期徒刑或者拘役，并处或者单处罚金；情节特别严重的，处三年以上七年以下有期徒刑，并处罚金。 非法侵入计算机信息系统罪 《刑法》第二百八十六条还规定，违反国家规定，对计算机信息系统功能进行删除、修改、增加、干扰，造成计算机信息系统不能正常运行，后果严重的，构成犯罪，处五年以下有期徒刑或者拘役；后果特别严重的，处五年以上有期徒刑。而违反国家规定，对计算机信息系统中存储、处理或者传输的数据和应用程序进行删除、修改、增加的操作，后果严重的，也构成犯罪，依照前款的规定处罚。 侵犯公民个人信息罪 《刑法》修正案（九）中将刑法第二百五十三条进行了修订，明确规定违反国家有关规定，向他人出售或者提供公民个人信息，情节严重的，构成犯罪；在未经用户许可的情况下，非法获取用户的个人信息，情节严重的也将构成“侵犯公民个人信息罪”。 根据《最高人民法院 最高人民检察院关于办理侵犯公民个人信息刑事案件适用法律若干问题的解释》第五条规定，对“情节严重”的解释，（1）非法获取、出售或者提供行踪轨迹信息、通信内容、征信信息、财产信息五十条以上的；（2）非法获取、出售或者提供住宿信息、通信记录、健康生理信息、交易信息等其他可能影响人身、财产安全的公民个人信息五百条以上的；（3）非法获取、出售或者提供第三项、第四项规定以外的公民个人信息五千条以上的便构成“侵犯公民个人信息罪”所要求的“情节严重”。 侵犯商业秘密罪 《反不正当竞争法》第九条，以不正当手段获取他人商业秘密的行为即已经构成侵犯商业秘密。而后续如果进一步利用，或者公开该等信息，则构成对他人商业秘密的披露和使用，同样构成对权利人的商业秘密的侵犯。 网络安全法 《网络安全法》第四十四条 任何个人和组织不得窃取或者以其他非法方式获取个人信息。因此，如果爬虫在未经用户同意的情况下大量抓取用户的个人信息，则有可能构成非法收集个人信息的违法行为。 民法总则 《民法总则》第111条任何组织和个人需要获取他人个人信息的，应当依法取得并确保信息安全。不得非法收集、使用、加工、传输他人个人信息 专业律师发表的相关观点周 浩：利用网络爬虫获取数据的刑事责任分析 金 杜：数据之争：网络爬虫涉及的法律问题","tags":[{"name":"爬虫","slug":"爬虫","permalink":"https://www.qiudx.top/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"如何搭个博客网站","date":"2019-12-31T14:53:20.000Z","path":"2019/12/31/如何搭个博客网站/","text":"概要 Hexo 编写博客 github 域名 hexo介绍主页： https://hexo.io/zh-cn/主页中有非常详细的介绍 hexo 可以理解为是基于node.js制作的一个博客工具，不是我们理解的一个开源的博客系统。 hexo 正常来说，不需要部署到我们的服务器上，我们的服务器上保存的，其实是基于在hexo通过markdown编写的文章，然后hexo帮我们生成静态的html页面，然后，将生成的html上传到我们的服务器。简而言之：hexo是个静态页面生成、上传的工具。 安装hexo依赖node环境，安装hexo前请先安装Nodejs 1234npm install hexo-cli -ghexo init blogcd blognpm install 以后可能会用到 1234## 百度网站地图插件npm install hexo-generator-baidu-sitemap --save-dev## 搜索插件npm install hexo-generator-json-content@2.2.0 --save 编写博客1hexo new xxx 启动1hexo s 主题默认的主题有些丑，可以在https://hexo.io/themes/ 这个网站挑选自己喜欢的主题 github博客写好了之后，我们用利用GitHub来托管静态网站 账号注册先去github官网上注册一个账号，根据提示最后一步别忘了激活你的邮箱 创建仓库注册完后选择start a project创建一个公开的仓库 注意：项目名字固定且唯一，username.github.io 例如我的是qiudxx.github.io然后点击生成 发布 先安装git插件： 1npm install hexo-deployer-git --save 修改_config.yml文件: 1234deploy: - type: git repository: git@github.com:qiudxx/qiudxx.github.io.git,master branch: master 你要确保你本地能git push到服务端，需要配置本地的ssh github私钥。没有操作过的同学，请自行搜索。 1hexo g -d 这样应该就能在你的github上看到上传的代码了，这时看到的应该是纯静态的一个站点。 这时可以访问https://username.github.io 看到博客内容 例如我的地址是：https://qiudxx.github.io 我配置了域名，会自动跳转到我的域名 域名阿里云,百度云,腾讯云等云服务商会提供一些非常实惠的域名； 1元就能买到很多不错的域名。 进入github刚创建的项目，点击Setting 在GitHub Pages设置中Custom domain设置为你的域名 进入域名服务设置 增加两条记录 记录类型为cname 记录值为你博客的访问地址 开启https","tags":[{"name":"blog","slug":"blog","permalink":"https://www.qiudx.top/tags/blog/"}]},{"title":"Restful","date":"2019-12-28T16:05:42.000Z","path":"2019/12/29/Restful/","text":"概要 什么是Restful 原则条件 Restful应用特点 什么是Restful​ 一种软件架构风格，设计风格而不是标准，只是提供了一组设计原则和约束条件。它主要用于客户端和服务器交互类的软件。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。 ​ REST（英文：Representational State Transfer，简称REST）描述了一个架构样式的网络系统，比如 web 应用程序。它首次出现在 2000 年 Roy Fielding 的博士论文中，他是 HTTP 规范的主要编写者之一。在目前主流的三种Web服务交互方案中，REST相比于SOAP（Simple Object Access protocol，简单对象访问协议）以及XML-RPC更加简单明了，无论是对URL的处理还是对Payload的编码，REST都倾向于用更加简单轻量的方法设计和实现。值得注意的是REST并没有一个明确的标准，而更像是一种设计的风格。 原则条件 REST 指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就是 RESTful。 Web 应用程序最重要的 REST 原则是，客户端和服务器之间的交互在请求之间是无状态的。从客户端到服务器的每个请求都必须包含理解请求所必需的信息。如果服务器在请求之间的任何时间点重启，客户端不会得到通知。此外，无状态请求可以由任何可用服务器回答，这十分适合云计算之类的环境。客户端可以缓存数据以改进性能。 在服务器端，应用程序状态和功能可以分为各种资源。资源是一个有趣的概念实体，它向客户端公开。资源的例子有：应用程序对象、数据库记录、算法等等。每个资源都使用 URI (Universal Resource Identifier) 得到一个唯一的地址。所有资源都共享统一的接口，以便在客户端和服务器之间传输状态。使用的是标准的 HTTP 方法，比如 GET、PUT、POST 和DELETE。Hypermedia 是应用程序状态的引擎，资源表示通过超链接互联。 Restful应用特点 从资源的角度来考察整个网络，每个资源有唯一标识 使用通用的连接器接口操作资源 对资源的操作不会改变资源标识 连接协议具有无状态性 能够使用 Cache 机制来增进性能","tags":[{"name":"面试","slug":"面试","permalink":"https://www.qiudx.top/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Token","date":"2018-07-01T14:56:35.000Z","path":"2018/07/01/Token/","text":"概要 Token是干什么 Token是怎么做的？ Token长什么样子呢？ Token怎么使用呢？ Token是干什么 简称 JWT，在HTTP通信过程中，进行身份认证。 Token是怎么做的？ 客户端通过用户名和密码登录服务器； 服务端对客户端身份进行验证； 服务端对该用户生成Token，返回给客户端； 客户端将Token保存到本地浏览器 客户端发起请求，需要携带该Token； 服务端收到请求后，首先验证Token，之后返回数据。 注意： 服务端不需要保存Token，只需要对Token中携带的信息进行验证即可；无论客户端访问后台的那台服务器，只要可以通过用户信息的验证即可。 Token长什么样子呢？ 通过名字就可以看出来，是一个 json。 由三部分内容组成： 头(header)，一般很少改动直接使用默认的即可： 1234&#123; 'typ':'JWT', 'alg':'HS256'&#125; 肚子(playload),东西都装在肚子里，默认的内容有： 123456789&#123; 'iss':'签发者', 'sub':'面向的用户', 'aud':'接收方', 'exp': 过期时间, 'iat': 创建时间, 'nbf': 在什么时间之前，该Token不可用, 'jti':'Token唯一标识'&#125; 根据需要用户可以自己定义，Token 中传输的内容，一般会将用户名，角色等信息放到 Token 中。 尾(signature),前面两部分转为字符串后，使用 base64 编码，然后进行加密得到一个字符串。 1Token = 头（base64）+ 肚子（base64）+ 尾； Token怎么使用呢？利用Java封装的JJWT实现，下载jar地址为：http://maven.outofmemory.cn/io.jsonwebtoken/jjwt/0.6.0/ 还需要依赖包 jackson-annotations-2.5.0.jar、jackson-core-2.5.0.jar、jackson-databind-2.5.0.jar，地址：http://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-core/2.5.0 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.security.Key;import java.util.Date;import java.util.HashMap;import java.util.Map;import javax.crypto.spec.SecretKeySpec;import javax.xml.bind.DatatypeConverter;import io.jsonwebtoken.Claims;import io.jsonwebtoken.ExpiredJwtException;import io.jsonwebtoken.InvalidClaimException;import io.jsonwebtoken.JwtBuilder;import io.jsonwebtoken.Jwts;import io.jsonwebtoken.SignatureAlgorithm;public class JwtManager &#123; /** * 1、选择签名的算法 * 2、生成签名的密钥 * 3、构建Token信息 * 4、利用算法和密钥生成Token */ public static String createToken() &#123; SignatureAlgorithm signatureAlgorithm = SignatureAlgorithm.HS256; byte[] secretBytes = DatatypeConverter.parseBase64Binary(\"JWT-TOKEN\"); Key signingKey = new SecretKeySpec(secretBytes, signatureAlgorithm.getJcaName()); Map&lt;String, Object&gt; claims = new HashMap&lt;String, Object&gt;(); claims.put(\"username\", \"token\"); claims.put(\"role\", \"admin\"); JwtBuilder builder = Jwts.builder().setClaims(claims) .setId(\"tokenid\") .setIssuedAt(new Date()) .setExpiration(new Date(System.currentTimeMillis()+10*60*1000)) .signWith(signatureAlgorithm, signingKey); return builder.compact(); &#125; public static Claims parseToken(String token) &#123; return Jwts.parser().setSigningKey(DatatypeConverter.parseBase64Binary(\"JWT-TOKEN\")) .parseClaimsJws(token).getBody(); &#125; public static void validateToken(String token) &#123; try&#123; Claims claims = parseToken(token); String username = claims.get(\"username\").toString(); String role = claims.get(\"role\").toString(); String tokenid = claims.getId(); System.out.println(\"[username]:\"+username); System.out.println(\"[role]:\"+role); System.out.println(\"[tokenid]:\"+tokenid); &#125; catch(ExpiredJwtException e) &#123; System.out.println(\"token expired\"); &#125; catch (InvalidClaimException e) &#123; System.out.println(\"token invalid\"); &#125; catch (Exception e) &#123; System.out.println(\"token error\"); &#125; &#125; public static void main(String[] args) &#123; validateToken(createToken()); &#125;&#125;","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"}]},{"title":"elasticsearch学习","date":"2018-06-13T10:57:53.000Z","path":"2018/06/13/elasticsearch学习/","text":"概要 是什么 名词解释 elasticsearch简单使用 elasticsearch学习是什么 分布式的实时文件存储，每个字段都被索引并可被搜索 分布式的实时分析搜索引擎 可以扩展到上百台服务器，处理PB级结构化或非结构化数据 名词解释 index 类似于MySQL的数据库 type 类似于MySQL的表 document 类似于MySQL的行 简单入门 依赖 1234567891011121314151617181920212223242526272829303132333435&lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.0.12&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;6.2.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;transport&lt;/artifactId&gt; &lt;version&gt;6.2.4&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件 application.properties 1234567# Elasticsearch# 9200端口是用来让HTTP REST API来访问ElasticSearch，而9300端口是传输层监听的默认端口elasticsearch.ip&#x3D;127.0.0.1elasticsearch.port&#x3D;9300# 默认值是核心线程数*4elasticsearch.pool&#x3D;5elasticsearch.cluster.name&#x3D;qiudx_es_study es配置文件ElasticsearchConfig 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * 用于定义配置类，可替换xml配置文件 * * @author qiudx * @version $Id ElasticsearchConfig.java, v 0.1 2018-06-13 13:26 qiudx Exp $$ */@Configurationpublic class ElasticsearchConfig &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ElasticsearchConfig.class); /** * elk集群地址 */ @Value(\"$&#123;elasticsearch.ip&#125;\") private String hostName; /** * 端口 */ @Value(\"$&#123;elasticsearch.port&#125;\") private String port; /** * 集群名称 */ @Value(\"$&#123;elasticsearch.cluster.name&#125;\") private String clusterName; /** * 连接池 */ @Value(\"$&#123;elasticsearch.pool&#125;\") private String poolSize; /** * Bean name default 函数名字 */ @Bean(name = \"transportClient\") public TransportClient transportClient() &#123; LOGGER.info(\"Elasticsearch初始化开始。。。。。\"); TransportClient transportClient = null; try &#123; // 配置信息 Settings esSetting = Settings.builder() //集群名字 .put(\"cluster.name\", clusterName) //增加嗅探机制，找到ES集群 .put(\"client.transport.sniff\", true) //增加线程池个数，暂时设为5 .put(\"thread_pool.search.size\", Integer.parseInt(poolSize)) .build(); //配置信息Settings自定义 transportClient = new PreBuiltTransportClient(esSetting); TransportAddress transportAddress = new TransportAddress(InetAddress.getByName(hostName), Integer.valueOf(port)); transportClient.addTransportAddresses(transportAddress); &#125; catch (Exception e) &#123; LOGGER.error(\"elasticsearch TransportClient create error!!\", e); &#125; return transportClient; &#125;&#125; 工具类 对es操作进行封装 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309/** * @author qiudx * @version $Id ElasticsearchUtil.java, v 0.1 2018-06-13 13:29 qiudx Exp $$ */@Componentpublic class ElasticsearchUtil &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ElasticsearchUtil.class); private final TransportClient transportClient; private static TransportClient client; @Autowired public ElasticsearchUtil(TransportClient transportClient) &#123; this.transportClient = transportClient; &#125; /** * spring容器初始化的时候执行该方法 */ @PostConstruct public void init() &#123; client = this.transportClient; &#125; /** * 创建索引 */ public static boolean createIndex(String index) &#123; if (!isIndexExist(index)) &#123; LOGGER.info(\"Index is not exits!\"); &#125; CreateIndexResponse indexresponse = client.admin().indices().prepareCreate(index).execute().actionGet(); LOGGER.info(\"执行建立成功？\" + indexresponse.isAcknowledged()); return indexresponse.isAcknowledged(); &#125; /** * 删除索引 */ public static boolean deleteIndex(String index) &#123; if (!isIndexExist(index)) &#123; LOGGER.info(\"Index is not exits!\"); &#125; DeleteIndexResponse dResponse = client.admin().indices().prepareDelete(index).execute().actionGet(); if (dResponse.isAcknowledged()) &#123; LOGGER.info(\"delete index \" + index + \" successfully!\"); &#125; else &#123; LOGGER.info(\"Fail to delete index \" + index); &#125; return dResponse.isAcknowledged(); &#125; /** * 判断索引是否存在 */ public static boolean isIndexExist(String index) &#123; IndicesExistsResponse inExistsResponse = client.admin().indices().exists(new IndicesExistsRequest(index)).actionGet(); if (inExistsResponse.isExists()) &#123; LOGGER.info(\"Index [\" + index + \"] is exist!\"); &#125; else &#123; LOGGER.info(\"Index [\" + index + \"] is not exist!\"); &#125; return inExistsResponse.isExists(); &#125; /** * 数据添加，正定ID * * @param jsonObject 要增加的数据 * @param index 索引，类似数据库 * @param type 类型，类似表 * @param id 数据ID */ public static String addData(JSONObject jsonObject, String index, String type, String id) &#123; IndexResponse response = client.prepareIndex(index, type, id).setSource(jsonObject).get(); LOGGER.info(\"addData response status:&#123;&#125;,id:&#123;&#125;\", response.status().getStatus(), response.getId()); return response.getId(); &#125; /** * 数据添加 * * @param jsonObject 要增加的数据 * @param index 索引，类似数据库 * @param type 类型，类似表 */ public static String addData(JSONObject jsonObject, String index, String type) &#123; return addData(jsonObject, index, type, UUID.randomUUID().toString().replaceAll(\"-\", \"\").toUpperCase()); &#125; /** * 通过ID删除数据 * * @param index 索引，类似数据库 * @param type 类型，类似表 * @param id 数据ID */ public static void deleteDataById(String index, String type, String id) &#123; DeleteResponse response = client.prepareDelete(index, type, id).execute().actionGet(); LOGGER.info(\"deleteDataById response status:&#123;&#125;,id:&#123;&#125;\", response.status().getStatus(), response.getId()); &#125; /** * 通过ID 更新数据 * * @param jsonObject 要增加的数据 * @param index 索引，类似数据库 * @param type 类型，类似表 * @param id 数据ID */ public static void updateDataById(JSONObject jsonObject, String index, String type, String id) &#123; UpdateRequest updateRequest = new UpdateRequest(); updateRequest.index(index).type(type).id(id).doc(jsonObject); client.update(updateRequest); &#125; /** * 通过ID获取数据 * * @param index 索引，类似数据库 * @param type 类型，类似表 * @param id 数据ID * @param fields 需要显示的字段，逗号分隔（缺省为全部字段） */ public static Map&lt;String, Object&gt; searchDataById(String index, String type, String id, String fields) &#123; GetRequestBuilder getRequestBuilder = client.prepareGet(index, type, id); if (StrUtil.isNotEmpty(fields)) &#123; getRequestBuilder.setFetchSource(fields.split(\",\"), null); &#125; GetResponse getResponse = getRequestBuilder.execute().actionGet(); return getResponse.getSource(); &#125; /** * 使用分词查询,并分页 * * @param index 索引名称 * @param type 类型名称,可传入多个type逗号分隔 * @param startPage 当前页 * @param pageSize 每页显示条数 * @param query 查询条件 * @param fields 需要显示的字段，逗号分隔（缺省为全部字段） * @param sortField 排序字段 * @param highlightField 高亮字段 */ public static EsPage searchDataPage(String index, String type, int startPage, int pageSize, QueryBuilder query, String fields, String sortField, String highlightField) &#123; SearchRequestBuilder searchRequestBuilder = client.prepareSearch(index); if (StrUtil.isNotEmpty(type)) &#123; searchRequestBuilder.setTypes(type.split(\",\")); &#125; searchRequestBuilder.setSearchType(SearchType.QUERY_THEN_FETCH); // 需要显示的字段，逗号分隔（缺省为全部字段） if (StrUtil.isNotEmpty(fields)) &#123; searchRequestBuilder.setFetchSource(fields.split(\",\"), null); &#125; //排序字段 if (StrUtil.isNotEmpty(sortField)) &#123; searchRequestBuilder.addSort(sortField, SortOrder.DESC); &#125; // 高亮（xxx=111,aaa=222） if (StrUtil.isNotEmpty(highlightField)) &#123; HighlightBuilder highlightBuilder = new HighlightBuilder(); //highlightBuilder.preTags(\"&lt;span style='color:red' &gt;\");//设置前缀 //highlightBuilder.postTags(\"&lt;/span&gt;\");//设置后缀 // 设置高亮字段 highlightBuilder.field(highlightField); searchRequestBuilder.highlighter(highlightBuilder); &#125; //searchRequestBuilder.setQuery(QueryBuilders.matchAllQuery()); searchRequestBuilder.setQuery(query); // 分页应用 searchRequestBuilder.setFrom(startPage).setSize(pageSize); // 设置是否按查询匹配度排序 searchRequestBuilder.setExplain(true); //打印的内容 可以在 Elasticsearch head 和 Kibana 上执行查询 LOGGER.info(\"\\n&#123;&#125;\", searchRequestBuilder); // 执行搜索,返回搜索响应信息 SearchResponse searchResponse = searchRequestBuilder.execute().actionGet(); long totalHits = searchResponse.getHits().totalHits; long length = searchResponse.getHits().getHits().length; LOGGER.debug(\"共查询到[&#123;&#125;]条数据,处理数据条数[&#123;&#125;]\", totalHits, length); if (searchResponse.status().getStatus() == 200) &#123; // 解析对象 List&lt;Map&lt;String, Object&gt;&gt; sourceList = setSearchResponse(searchResponse, highlightField); return new EsPage(startPage, pageSize, (int) totalHits, sourceList); &#125; return null; &#125; /** * 使用分词查询 * * @param index 索引名称 * @param type 类型名称,可传入多个type逗号分隔 * @param query 查询条件 * @param size 文档大小限制 * @param fields 需要显示的字段，逗号分隔（缺省为全部字段） * @param sortField 排序字段 * @param highlightField 高亮字段 */ public static List&lt;Map&lt;String, Object&gt;&gt; searchListData(String index, String type, QueryBuilder query, Integer size, String fields, String sortField, String highlightField) &#123; SearchRequestBuilder searchRequestBuilder = client.prepareSearch(index); if (StrUtil.isNotEmpty(type)) &#123; searchRequestBuilder.setTypes(type.split(\",\")); &#125; if (StrUtil.isNotEmpty(highlightField)) &#123; HighlightBuilder highlightBuilder = new HighlightBuilder(); // 设置高亮字段 highlightBuilder.field(highlightField); searchRequestBuilder.highlighter(highlightBuilder); &#125; searchRequestBuilder.setQuery(query); if (StrUtil.isNotEmpty(fields)) &#123; searchRequestBuilder.setFetchSource(fields.split(\",\"), null); &#125; searchRequestBuilder.setFetchSource(true); if (StrUtil.isNotEmpty(sortField)) &#123; searchRequestBuilder.addSort(sortField, SortOrder.DESC); &#125; if (size != null &amp;&amp; size &gt; 0) &#123; searchRequestBuilder.setSize(size); &#125; //打印的内容 可以在 Elasticsearch head 和 Kibana 上执行查询 LOGGER.info(\"\\n&#123;&#125;\", searchRequestBuilder); SearchResponse searchResponse = searchRequestBuilder.execute().actionGet(); long totalHits = searchResponse.getHits().totalHits; long length = searchResponse.getHits().getHits().length; LOGGER.info(\"共查询到[&#123;&#125;]条数据,处理数据条数[&#123;&#125;]\", totalHits, length); if (searchResponse.status().getStatus() == 200) &#123; // 解析对象 return setSearchResponse(searchResponse, highlightField); &#125; return null; &#125; /** * 高亮结果集 特殊处理 */ private static List&lt;Map&lt;String, Object&gt;&gt; setSearchResponse(SearchResponse searchResponse, String highlightField) &#123; List&lt;Map&lt;String, Object&gt;&gt; sourceList = new ArrayList&lt;&gt;(); StringBuilder stringBuffer = new StringBuilder(); for (SearchHit searchHit : searchResponse.getHits().getHits()) &#123; searchHit.getSourceAsMap().put(\"id\", searchHit.getId()); if (StrUtil.isNotEmpty(highlightField)) &#123; System.out.println(\"遍历 高亮结果集，覆盖 正常结果集\" + searchHit.getSourceAsMap()); Text[] text = searchHit.getHighlightFields().get(highlightField).getFragments(); if (text != null) &#123; for (Text str : text) &#123; stringBuffer.append(str.string()); &#125; //遍历 高亮结果集，覆盖 正常结果集 searchHit.getSourceAsMap().put(highlightField, stringBuffer.toString()); &#125; &#125; sourceList.add(searchHit.getSourceAsMap()); &#125; return sourceList; &#125; &#125; 分页工具类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130/** * @author qiudx * @version $Id EsPage.java, v 0.1 2018-06-13 13:32 qiudx Exp $$ */public class EsPage &#123; /** * 当前页 */ private int currentPage; /** * 每页显示多少条 */ private int pageSize; /** * 总记录数 */ private int recordCount; /** * 本页的数据列表 */ private List&lt;Map&lt;String, Object&gt;&gt; recordList; /** * 总页数 */ private int pageCount; /** * 页码列表的开始索引（包含） */ private int beginPageIndex; /** * 页码列表的结束索引（包含） */ private int endPageIndex; /** * 只接受前4个必要的属性，会自动的计算出其他3个属性的值 */ public EsPage(int currentPage, int pageSize, int recordCount, List&lt;Map&lt;String, Object&gt;&gt; recordList) &#123; this.currentPage = currentPage; this.pageSize = pageSize; this.recordCount = recordCount; this.recordList = recordList; // 计算总页码 pageCount = (recordCount + pageSize - 1) / pageSize; // 计算 beginPageIndex 和 endPageIndex // &gt;&gt; 总页数不多于10页，则全部显示 if (pageCount &lt;= 10) &#123; beginPageIndex = 1; endPageIndex = pageCount; &#125;// &gt;&gt; 总页数多于10页，则显示当前页附近的共10个页码 else &#123;// 当前页附近的共10个页码（前4个 + 当前页 + 后5个） beginPageIndex = currentPage - 4; endPageIndex = currentPage + 5; // 当前面的页码不足4个时，则显示前10个页码 if (beginPageIndex &lt; 1) &#123; beginPageIndex = 1; endPageIndex = 10; &#125;// 当后面的页码不足5个时，则显示后10个页码 if (endPageIndex &gt; pageCount) &#123; endPageIndex = pageCount; beginPageIndex = pageCount - 10 + 1; &#125; &#125; &#125; public int getCurrentPage() &#123; return currentPage; &#125; public void setCurrentPage(int currentPage) &#123; this.currentPage = currentPage; &#125; public int getPageSize() &#123; return pageSize; &#125; public void setPageSize(int pageSize) &#123; this.pageSize = pageSize; &#125; public int getRecordCount() &#123; return recordCount; &#125; public void setRecordCount(int recordCount) &#123; this.recordCount = recordCount; &#125; public List&lt;Map&lt;String, Object&gt;&gt; getRecordList() &#123; return recordList; &#125; public void setRecordList(List&lt;Map&lt;String, Object&gt;&gt; recordList) &#123; this.recordList = recordList; &#125; public int getPageCount() &#123; return pageCount; &#125; public void setPageCount(int pageCount) &#123; this.pageCount = pageCount; &#125; public int getBeginPageIndex() &#123; return beginPageIndex; &#125; public void setBeginPageIndex(int beginPageIndex) &#123; this.beginPageIndex = beginPageIndex; &#125; public int getEndPageIndex() &#123; return endPageIndex; &#125; public void setEndPageIndex(int endPageIndex) &#123; this.endPageIndex = endPageIndex; &#125; &#125; 实体 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * @author qiudx * @version $Id EsModel.java, v 0.1 2018-06-13 13:40 qiudx Exp $$ */public class EsModel &#123; private String id; private String name; private int age; private Date date; /** * Getter method for property &lt;tt&gt;id&lt;/tt&gt;. * * @return property value of id */ public String getId() &#123; return id; &#125; /** * Setter method for property &lt;tt&gt;id&lt;/tt&gt;. * * @param id value to be assigned to property id */ public void setId(String id) &#123; this.id = id; &#125; /** * Getter method for property &lt;tt&gt;name&lt;/tt&gt;. * * @return property value of name */ public String getName() &#123; return name; &#125; /** * Setter method for property &lt;tt&gt;name&lt;/tt&gt;. * * @param name value to be assigned to property name */ public void setName(String name) &#123; this.name = name; &#125; /** * Getter method for property &lt;tt&gt;age&lt;/tt&gt;. * * @return property value of age */ public int getAge() &#123; return age; &#125; /** * Setter method for property &lt;tt&gt;age&lt;/tt&gt;. * * @param age value to be assigned to property age */ public void setAge(int age) &#123; this.age = age; &#125; /** * Getter method for property &lt;tt&gt;date&lt;/tt&gt;. * * @return property value of date */ public Date getDate() &#123; return date; &#125; /** * Setter method for property &lt;tt&gt;date&lt;/tt&gt;. * * @param date value to be assigned to property date */ public void setDate(Date date) &#123; this.date = date; &#125;&#125; 测试 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185/** * @author qiudx * @version $Id EsController.java, v 0.1 2018-06-13 13:36 qiudx Exp $$ */@RestController@EnableAutoConfiguration@RequestMapping(\"/es\")public class EsController &#123; /** * 测试索引 */ private String indexName = \"test_index\"; /** * 类型 */ private String esType = \"external\"; /** * http://127.0.0.1:8080/es/createIndex * 创建索引 */ @RequestMapping(\"/createIndex\") public String createIndex() &#123; if (!ElasticsearchUtil.isIndexExist(indexName)) &#123; ElasticsearchUtil.createIndex(indexName); &#125; else &#123; return \"索引已经存在\"; &#125; return \"索引创建成功\"; &#125; /** * 插入记录 */ @RequestMapping(\"/insertJson\") public String insertJson() &#123; JSONObject jsonObject = new JSONObject(); jsonObject.put(\"id\", DateUtil.formatDate(new Date())); jsonObject.put(\"age\", 25); jsonObject.put(\"name\", \"j-\" + new Random(100).nextInt()); jsonObject.put(\"date\", new Date()); return ElasticsearchUtil.addData(jsonObject, indexName, esType, jsonObject.getString(\"id\")); &#125; /** * 插入记录 */ @RequestMapping(\"/insertModel\") public String insertModel() &#123; EsModel esModel = new EsModel(); esModel.setId(DateUtil.formatDate(new Date())); esModel.setName(\"m-\" + new Random(100).nextInt()); esModel.setAge(30); esModel.setDate(new Date()); JSONObject jsonObject = (JSONObject) JSONObject.toJSON(esModel); return ElasticsearchUtil.addData(jsonObject, indexName, esType, jsonObject.getString(\"id\")); &#125; /** * 删除记录 */ @RequestMapping(\"/delete\") public String delete(String id) &#123; if (StrUtil.isNotBlank(id)) &#123; ElasticsearchUtil.deleteDataById(indexName, esType, id); return \"删除id=\" + id; &#125; else &#123; return \"id为空\"; &#125; &#125; /** * 更新数据 */ @RequestMapping(\"/update\") public String update(String id) &#123; if (StrUtil.isNotBlank(id)) &#123; JSONObject jsonObject = new JSONObject(); jsonObject.put(\"id\", id); jsonObject.put(\"age\", 31); jsonObject.put(\"name\", \"修改\"); jsonObject.put(\"date\", new Date()); ElasticsearchUtil.updateDataById(jsonObject, indexName, esType, id); return \"id=\" + id; &#125; else &#123; return \"id为空\"; &#125; &#125; /** * 获取数据 * http://127.0.0.1:8080/es/getData?id=2018-04-25%2016:33:44 */ @RequestMapping(\"/getData\") public String getData(String id) &#123; if (StrUtil.isNotBlank(id)) &#123; Map&lt;String, Object&gt; map = ElasticsearchUtil.searchDataById(indexName, esType, id, null); return JSONObject.toJSONString(map); &#125; else &#123; return \"id为空\"; &#125; &#125; /** * 查询数据 * 模糊查询 */ @RequestMapping(\"/queryMatchData\") @ResponseBody public String queryMatchData() &#123; BoolQueryBuilder boolQuery = QueryBuilders.boolQuery(); boolQuery.must(QueryBuilders.matchQuery(\"name\", \"修\")); List&lt;Map&lt;String, Object&gt;&gt; list = ElasticsearchUtil.searchListData(indexName, esType, boolQuery, 10, null, null, null); return JSONObject.toJSONString(list); &#125; /** * 通配符查询数据 * 通配符查询 ?用来匹配1个任意字符，*用来匹配零个或者多个字符 */ @RequestMapping(\"/queryWildcardData\") public String queryWildcardData() &#123; QueryBuilder queryBuilder = QueryBuilders.wildcardQuery(\"name.keyword\", \"修*\"); List&lt;Map&lt;String, Object&gt;&gt; list = ElasticsearchUtil.searchListData(indexName, esType, queryBuilder, 10, null, null, null); return JSONObject.toJSONString(list); &#125; /** * 正则查询 */ @RequestMapping(\"/queryRegexpData\") public String queryRegexpData() &#123; QueryBuilder queryBuilder = QueryBuilders.regexpQuery(\"name.keyword\", \"j--[0-9]&#123;1,11&#125;\"); List&lt;Map&lt;String, Object&gt;&gt; list = ElasticsearchUtil.searchListData(indexName, esType, queryBuilder, 10, null, null, null); return JSONObject.toJSONString(list); &#125; /** * 查询数字范围数据 */ @RequestMapping(\"/queryIntRangeData\") public String queryIntRangeData() &#123; BoolQueryBuilder boolQuery = QueryBuilders.boolQuery(); boolQuery.must(QueryBuilders.rangeQuery(\"age\").from(31) .to(32)); List&lt;Map&lt;String, Object&gt;&gt; list = ElasticsearchUtil.searchListData(indexName, esType, boolQuery, 10, null, null, null); return JSONObject.toJSONString(list); &#125; /** * 查询日期范围数据 */ @RequestMapping(\"/queryDateRangeData\") public String queryDateRangeData() &#123; BoolQueryBuilder boolQuery = QueryBuilders.boolQuery(); boolQuery.must(QueryBuilders.rangeQuery(\"date\").from(\"2018-04-25T08:33:44.840Z\") .to(\"2018-04-25T10:03:08.081Z\")); List&lt;Map&lt;String, Object&gt;&gt; list = ElasticsearchUtil.searchListData(indexName, esType, boolQuery, 10, null, null, null); return JSONObject.toJSONString(list); &#125; /** * 查询分页 * * @param startPage 第几条记录开始 * 从0开始 * 第1页 ：http://127.0.0.1:8080/es/queryPage?startPage=0&amp;pageSize=2 * 第2页 ：http://127.0.0.1:8080/es/queryPage?startPage=2&amp;pageSize=2 * @param pageSize 每页大小 */ @RequestMapping(\"/queryPage\") public String queryPage(String startPage, String pageSize) &#123; if (StrUtil.isNotBlank(startPage) &amp;&amp; StrUtil.isNotBlank(pageSize)) &#123; BoolQueryBuilder boolQuery = QueryBuilders.boolQuery(); boolQuery.must(QueryBuilders.rangeQuery(\"date\").from(\"2018-04-25T08:33:44.840Z\") .to(\"2018-04-25T10:03:08.081Z\")); EsPage list = ElasticsearchUtil.searchDataPage(indexName, esType, Integer.parseInt(startPage), Integer.parseInt(pageSize), boolQuery, null, null, null); return JSONObject.toJSONString(list); &#125; else &#123; return \"startPage或者pageSize缺失\"; &#125; &#125;&#125;","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://www.qiudx.top/tags/spring-boot/"}]},{"title":"WebSocket使用心得","date":"2018-02-22T08:44:08.000Z","path":"2018/02/22/WebSocket使用心得/","text":"概要 2018年第一天上班 WebSocket 简介 spring-boot-websocket的使用 前言: 2018年上班第一天,没什么事,就将前些天写的一个关于智能面试机器人项目中使用到的websoket总结如下: WebSocket 简介WebSocket是HTML5一种新的协议。它实现了浏览器与服务器全双工通信，能更好的节省服务器资源和带宽并达到实时通讯，它建立在TCP之上，同HTTP一样通过TCP来传输数据，但是它和HTTP最大不同是： WebSocket 是一种双向通信协议，在建立连接后，WebSocket服务器和Browser/Client Agent都能主动的向对方发送或接收数据，就像Socket一样； WebSocket 需要类似TCP的客户端和服务器端通过握手连接，连接成功后才能相互通信。 spring-boot-websocket的使用maven依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-websocket&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件1234567891011121314@Componentpublic class MyEndpointConfigure extends ServerEndpointConfig.Configurator implements ApplicationContextAware &#123; private static BeanFactory context; @Override public &lt;T&gt; T getEndpointInstance(Class&lt;T&gt; clazz) &#123; return context.getBean(clazz); &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; MyEndpointConfigure.context = applicationContext; &#125;&#125; 123456789@Configurationpublic class WebSocketConfig &#123; @Bean public ServerEndpointExporter serverEndpointExporter() &#123; return new ServerEndpointExporter(); &#125;&#125; 核心websocket特别注意: 不能使用默认的ServerEndpointConfig.Configurator.class,不然会导致服务无法注入 1234567891011121314151617181920212223242526272829303132@ServerEndpoint(value = \"/websocket\", configurator = MyEndpointConfigure.class)@Componentpublic class WebSocket &#123; /** * 成功建立连接调用的方法. */ @OnOpen public void onOpen(Session session) &#123; &#125; /** * 连接关闭调用的方法. */ @OnClose public void onClose(Session session) &#123; &#125; /** * 收到客户端消息后调用的方法. */ @OnMessage public void onMessage(String message, Session session) &#123; &#125; /** * 发生错误时调用. */ @OnError public void onError(Session session, Throwable error) &#123; &#125;&#125;","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://www.qiudx.top/tags/spring-boot/"}]},{"title":"Feign的简单使用","date":"2017-12-20T08:41:23.000Z","path":"2017/12/20/Feign的简单使用/","text":"概要 Feign简介 Feign简单使用 Feign简介Feign是一个声明式的web 服务客户端；它支持可插拔的注解，包含Feign注解和JAX-RS注解；并且支持可插拔的编码、解码； Feign使用maven依赖123456789101112131415161718&lt;!--用于feign的编解码--&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-gson&lt;/artifactId&gt; &lt;version&gt;9.5.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--feign的核心依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-core&lt;/artifactId&gt; &lt;version&gt;8.18.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--用于feign的请求--&gt;&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt; &lt;version&gt;8.18.0&lt;/version&gt;&lt;/dependency&gt; 服务消费段(自定义接口)1234public interface RemoteService &#123; @RequestLine(\"GET /getUser?name=&#123;name&#125;&amp;age=&#123;age&#125;\") User getUser(@Param(\"name\") String name, @Param(\"age\") int age);&#125; 服务生产端12345678910@RestControllerpublic class FeignController &#123; @GetMapping(\"getUser\") public User getUser(@RequestParam String name, @RequestParam int age) &#123; User user = new User(); user.setAge(age); user.setName(name); return user; &#125;&#125; 测试(服务消费段)1234567891011121314public class FeignControllerTest &#123; @Test public void test() &#123; RemoteService remoteService = Feign.builder() .client(new OkHttpClient()) .decoder(new GsonDecoder()) .encoder(new GsonEncoder()) .options(new Request.Options(1000, 2000)) .retryer(new Retryer.Default(1000, 2000, 2)) .target(RemoteService.class, \"http://127.0.0.1:8080\"); User user = remoteService.getUser(\"qiudx\", 23); System.out.println(user); &#125;&#125; OkHttpClient使用OkHttp来发送Feign的请求,OkHttp支持SPDY(SPDY是Google开发的基于TCP的传输层协议,用以最小化网络延迟,提升网络速度,优化用户的网络使用体验),并有更好的控制http请求。 Feign.builder()允许你自定义一些额外的配置,比如说如何解码一个响应。假如有接口方法返回的消息不是Response,String,byte[]或者void类型的,那么你需要配置一个非默认的解码器 options方法指定连接超时时长及响应超时时长 retryer方法指定重试策略 target方法绑定接口与服务端地址","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"}]},{"title":"令牌桶限流","date":"2017-12-07T08:45:40.000Z","path":"2017/12/07/令牌桶限流/","text":"概要 在项目中引入Guava相关包 创建拦截器 添加拦截器 测试 在使用SpringBoot做接口访问如何做接口的限流，这里我们可以使用google的Guava包来实现. 在项目中引入Guava相关包12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;23.5-jre&lt;/version&gt;&lt;/dependency&gt; 创建拦截器123456789101112131415161718192021222324252627282930313233343536373839404142public class AuthInterceptor extends HandlerInterceptorAdapter &#123; enum LimiterTypeEnum &#123; DROP,//丢弃 WAIT //等待 &#125; //限流器 private RateLimiter rateLimiter; //限流类型 private LimiterTypeEnum limiterType; /** * @param permitsPerSecond 限流量 (每秒处理量) * @param limiterType 限流类型 */ public AuthInterceptor(int permitsPerSecond, LimiterTypeEnum limiterType) &#123; this.rateLimiter = RateLimiter.create(permitsPerSecond); this.limiterType = limiterType; &#125; /** * @param permitsPerSecond 每秒新增的令牌数(这个是平滑增长,有一个预热过程) * @param limiterType 限流类型 */ public AuthInterceptor(double permitsPerSecond, LimiterTypeEnum limiterType) &#123; this.rateLimiter = RateLimiter.create(permitsPerSecond, 1, TimeUnit.SECONDS); this.limiterType = limiterType; &#125; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) &#123; if (Objects.equals(limiterType, LimiterTypeEnum.DROP)) &#123; return rateLimiter.tryAcquire(); //false为被限流 &#125; else &#123; rateLimiter.acquire();//一直等待,直到拿到令牌 return true; &#125; &#125;&#125; 添加拦截器123456789@Configurationpublic class AuthHandlerAdapter extends WebMvcConfigurerAdapter &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new AuthInterceptor(10, AuthInterceptor.LimiterTypeEnum.DROP)) .addPathPatterns(\"/*\"); &#125;&#125; 测试 controller 12345678@RestControllerpublic class TestController &#123; @GetMapping public String TestGetString() &#123; return \"爱生活,爱java\"; &#125;&#125; 并发请求 12345678910111213141516171819202122public class RequestTest &#123; public static void main(String[] args) &#123; HttpClient httpClient = new HttpClient(\"http://127.0.0.1:8080\", 2000, 2000); IntStream.range(0, 1000).forEach(value -&gt; &#123; testSend(httpClient); try &#123; TimeUnit.MILLISECONDS.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); &#125; public static void testSend(HttpClient httpClient) &#123; try &#123; httpClient.sendGet(\"UTF-8\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"}]},{"title":"Spring Boot自定义拦截器","date":"2017-12-06T08:25:08.000Z","path":"2017/12/06/Spring-Boot自定义拦截器/","text":"概要 HandlerInterceptor介绍 spring boot自定义拦截器实现 HandlerInterceptor介绍Spring提供的拦截器Interceptor与Servlet中的Filter不同的是, Interceptor采用AOP的方式在Servlet的service方法执行之前进行拦截, 可以进行更精细的控制 Interceptor中有如下方法: preHandle: 在Controller处理之前调用, 返回false时整个请求结束 postHandle: 在Controller调用之后执行, 但它会在DispatcherServlet进行视图的渲染之前执行, 也就是说在这个方法中你可以对ModelAndView进行操作 afterCompletion: 在整个请求完成之后执行, 也就是DispatcherServlet已经渲染了视图之后执行; 这个方法的主要作用是用于清理资源的 afterConcurrentHandlingStarted: 这个方法是AsyncHandlerInterceptor接口中添加的. 当Controller中有异步请求方法的时候会触发该方法, 异步请求先支持preHandle、然后执行afterConcurrentHandlingStarted, 异步线程完成之后执行会再执行preHandle、postHandle、afterCompletion关于最后那个方法, 举个列子:123456789@RestControllerpublic class ExampleController &#123; @RequestMapping(\"/\") DeferredResult&lt;String&gt; home() &#123; DeferredResult&lt;String&gt; dr = new DeferredResult&lt;String&gt;(); dr.setResult(\"成功\"); return dr; &#125;&#125; 上面这样的Controller里面有个异步结果, 则拦截器的执行顺序将是: preHandle -&gt; afterConcurrentHandlingStarted -&gt; preHandle -&gt; postHandle -&gt; afterCompletion. 如果把dr.setResult(“成功”); 这句删掉, 将只执行preHandle -&gt; afterConcurrentHandlingStarted 可以认为, afterConcurrentHandlingStarted是返回异步结果时调用(此时异步结果里不需要有数据), 而postHandle必须是返回的结果执行完, 异步结果中有数据了(dr.setResult)才调用 spring boot自定义拦截器实现 拦截器的编写 12345678910111213141516171819202122232425262728293031323334353637383940414243public class AuthInterceptor extends HandlerInterceptorAdapter &#123; /** * 前置检查 */ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; if (!handler.getClass().isAssignableFrom(HandlerMethod.class)) &#123; return true; &#125; String ip = request.getRemoteAddr(); long startTime = System.currentTimeMillis(); request.setAttribute(\"requestStartTime\", startTime); HandlerMethod handlerMethod = (HandlerMethod) handler; Method method = handlerMethod.getMethod(); System.out.println(\"用户:\" + ip + \",访问目标:\" + method.getDeclaringClass().getName() + \".\" + method.getName()); return true; &#125; /** * Controller调用之后执行 */ @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) &#123; HandlerMethod handlerMethod = (HandlerMethod) handler; Method method = handlerMethod.getMethod(); long startTime = (Long) request.getAttribute(\"requestStartTime\"); long endTime = System.currentTimeMillis(); long executeTime = endTime - startTime; // log it if (executeTime &gt; 1000) &#123; System.out.println(\"[\" + method.getDeclaringClass().getName() + \".\" + method.getName() + \"] 执行耗时 : \" + executeTime + \"ms\"); &#125; else &#123; System.out.println(\"[\" + method.getDeclaringClass().getSimpleName() + \".\" + method.getName() + \"] 执行耗时 : \" + executeTime + \"ms\"); &#125; &#125;&#125; 创建配置类继承WebMvcConfigurerAdapter 12345678910111213141516171819202122232425262728@Configurationpublic class AuthHandlerAdapter extends WebMvcConfigurerAdapter &#123; /** * 拦截器 * 由于项目集成了swagger,这里直接不拦截swagger的相关请求 */ @Override public void addInterceptors(InterceptorRegistry registry) &#123; //AuthInterceptor就是我们自定义的拦截器 registry.addInterceptor(new AuthInterceptor()) .addPathPatterns(\"/**\") .excludePathPatterns(\"/swagger-ui.html\") .excludePathPatterns(\"/swagger-resources/**\") .excludePathPatterns(\"/v2/api-docs\"); &#125; /** * 资源处理器 * swagger会和freemarker的静态资源路径冲突因此需配置swagger的资源处理器 */ @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler(\"/swagger-ui.html\") .addResourceLocations(\"classpath:/META-INF/resources/\"); registry.addResourceHandler(\"/webjars/**\") .addResourceLocations(\"classpath:/META-INF/resources/webjars/\"); &#125;&#125;","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://www.qiudx.top/tags/spring-boot/"}]},{"title":"使用FactoryBean来配置特定Bean","date":"2017-12-06T07:55:43.000Z","path":"2017/12/06/使用FactoryBean来配置特定Bean/","text":"概要 创建实现FactoryBean的工厂 在xml配置bean 使用bean 有时我们需要创建一些特定功能的bean,该如何做呢? 创建实现FactoryBean的工厂 123456789101112131415161718192021222324252627public class ProxyFactoryBean&lt;T&gt; implements FactoryBean&lt;T&gt; &#123; private Class&lt;T&gt; proxyInterface; @Autowired private QrpcProxy qrpcProxy; public ProxyFactoryBean() &#123; &#125; public ProxyFactoryBean(Class&lt;T&gt; proxyInterface) &#123; this.proxyInterface = proxyInterface; &#125; @Override public T getObject() &#123; return qrpcProxy.create(proxyInterface); &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return this.proxyInterface; &#125; @Override public boolean isSingleton() &#123; return true; &#125;&#125; 在xml配置bean 123&lt;bean id=\"testService\" class=\"com.qrpc.server.utils.ProxyFactoryBean\"&gt; &lt;constructor-arg value=\"com.qrpc.api.facade.TestService\"/&gt; &lt;/bean&gt; 使用 123456789101112@RestControllerpublic class TestController &#123; @Autowired private TestService testService; @GetMapping(BASE_GETSTRING) public String getString() &#123; return testService.getString(); &#125;&#125;","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://www.qiudx.top/tags/spring/"}]},{"title":"spring boot自定义配置文件的读取","date":"2017-12-05T08:11:20.000Z","path":"2017/12/05/spring-boot自定义配置文件的读取/","text":"概要 Environment读取配置文件 Configurable方式读取配置文件 @PropertySource注解方式读取配置文件 使用@ConfigurationProperties读取配置文件 在spring boot种自定义配置文件的读取很方便，不用在写propert的读取类来读取配置文件信息。 下面是我试过的读取springboot读取配置文件的几种方法： 准备： 在application.yml文件种加入配置信息： 12hank: testConfig: TestDriver 新建立配置文件 dbConfig.properties 12345jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/testjdbc.username=rootjdbc.password=rootorg.hank.testconfig=testConfig 测试: Environment读取配置文件 12345678@Autowiredprivate Environment env;@Testpublic void testConfigDefault() &#123; logger.info(\"Environment get default properties:\" + env.getProperty(\"hank.testConfig\")); logger.info(\"Environment get self properties:\" + env.getProperty(\"jdbc.driver\"));&#125; 测试结果 12Environment get default properties:TestDriverEnvironment get self properties:null 结论：也就是说Environment自带的只能读取默认的配置文件里面的配置信息，自定义的配置文件在Environment是读取不了的。况且在application.yml配置的都是系统自身的项，也就是不随系统环境改变而改变的配置项。一些易变的配置项我们还是自定义文件的比较好。我一般不会这么配置。 Configurable方式读取配置文件 建立类ConfigDefault 注解@Configurable 123456789101112@Component@Configurablepublic class ConfigDefault &#123; @Value(\"$&#123;hank.testConfig&#125;\") private String hankConfig; @Value(\"$&#123;org.hank.testconfig&#125;\") private String selfConfig; getter and setter....&#125; 测试： 1234567@Autowiredprivate ConfigDefault configDefault;@Testpublic void testConfigDefault() &#123; logger.info(\"defualt config--hank.testConfig:\" + configDefault.getHankConfig()); logger.info(\"self config--org.hank.testconfig:\" + configDefault.getSelfConfig());&#125; 测试结果：直接报错，Could not resolve placeholder ‘org.hank.testconfig’ in value “${org.hank.testconfig}” 也就说application.yml文件中没有org.hank.testconfig这配置项，所以在类上加@Configurable也是默认只读取application.yml文件的配置项 @PropertySource注解方式读取配置文件 新建model类： 1234567891011121314151617181920@Component@PropertySource(\"classpath:dbConfig.properties\")public class DataBaseConfig &#123; @Value(\"$&#123;jdbc.driver&#125;\") private String driver; @Value(\"$&#123;jdbc.url&#125;\") private String url; @Value(\"$&#123;jdbc.username&#125;\") private String userName; @Value(\"$&#123;jdbc.password&#125;\") private String password; @Value(\"$&#123;hank.testConfig&#125;\") //测试默认配置文件 private String hankConfig; getter and setter...&#125; 测试： 1234567@Autowiredprivate DataBaseConfig config;@Testpublic void testGetDataBaseConfig() &#123; logger.info(\"self Config Driver:\" + config.getDriver()); logger.info(\"default config hank.testConfig:\" + config.getHankConfig());&#125; 测试结果： 12self Config Driver:com.mysql.jdbc.Driverdefault config hank.testConfig:TestDriver 可以看出连同默认配置的信息也读取到了 结论：用@PropertySource(“classpath:dbConfig.properties”) 指定自定义配置文件路径就可以读取到自定义的配置文件信息，而对于默认配置文件application.yml我们也能在读取自定义配置文件的同时读取到默认配置文件的信息。 以上就是三中读取配置文件的方式，可以看到要想读取自定义的配置文件，就必须要注解指定配置文件路径。 使用@ConfigurationProperties读取配置文件 特別注意： 需要引入spring-boot-configuration-processor依赖 这种方法适合读取大量配置属性， @ConfigurationProperties注解的实体类必须有get/set方法 新建一个实体类： 12345678910@ConfigurationProperties(prefix = \"test\", locations = \"classpath:test.properties\")@Datapublic class Test &#123; private String one; private String two; private String three; private String four; private String five;&#125; 配置文件test.properties 12345test.one=onetest.two=twotest.three=threetest.four=fourtest.five=five 测试 123456789101112@RestController@EnableConfigurationProperties(Test.class)public class HelloController &#123; @Resource private Test test; @RequestMapping(\"/hello\") public String hello() &#123; return test.toString(); &#125;&#125; 結果 1Test&#123;one='one', two='two', three='three', four='four', five='five'&#125;","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://www.qiudx.top/tags/spring-boot/"}]},{"title":"MongoDB基本使用","date":"2017-11-20T12:23:15.000Z","path":"2017/11/20/MongoDB基本使用/","text":"概要 MongoDB是什么 NoSql是什么 为什么要使用NoSql MongoDB的特点 Spring整合MongoDB springboot项目 非springboot项目 相关实体类注解的解释 MongoDB简介MongoDB是什么 MongoDB是使用C++编写,开源的,面向文档的NoSql(Not Only SQL)数据库 NoSql是什么 NoSql(not only sql)是非关系型数据库的统称,常见的NoSql有Redis,MongoDB,Hbase,Cassandra等 为什么要使用NoSql 为了解决常规数据库以下问题 高并发下读写压力大 海量数据的高效存储和访问 数据库的高可用和高拓展性 MongoDB的特点 高性能易于使用,易于拓展 面向集合存储 支持动态查询,支持索引 支持分片 Spring整合MongoDB springboot项目 依赖 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 在application.perproties/yml配置mongodb的连接地址 1spring.data.mongodb.uri=mongodb://127.0.0.1:27017/myMongoDB 创建存储的User实体 123456789101112131415161718192021public class User &#123; @Id private Long id; private String username; private Integer age; public User(Long id, String username, Integer age) &#123; this.id = id; this.username = username; this.age = age; &#125; @Override public String toString() &#123; return \"User&#123;\" + \"id=\" + id + \", username='\" + username + '\\'' + \", age=\" + age + '&#125;'; &#125;&#125; 实现User的数据访问对象 123public interface UserRepository extends MongoRepository&lt;User, Long&gt; &#123; User findByUsername(String username);&#125; 测试 1234567891011121314151617181920212223242526272829303132@SpringBootTest@RunWith(SpringRunner.class)public class MongodbConnectionTestTest &#123; @Autowired private UserRepository userRepository; @Autowired protected MongoTemplate mongoOperations; @Test public void test() throws Exception &#123; // 创建三个User，并验证User总数 userRepository.save(new User(1L, \"didi\", 30)); userRepository.save(new User(2L, \"mama\", 40)); userRepository.save(new User(3L, \"kaka\", 50)); Assert.assertEquals(3, userRepository.findAll().size()); // 删除一个User，再验证User总数 User u = userRepository.findOne(1L); userRepository.delete(u); Assert.assertEquals(2, userRepository.findAll().size()); // 删除一个User，再验证User总数 u = userRepository.findByUsername(\"mama\"); userRepository.delete(u); Assert.assertEquals(1, userRepository.findAll().size()); &#125; @Test public void test1() throws Exception &#123; List&lt;User&gt; users = mongoOperations.findAll(User.class); users.forEach(System.out::println); &#125;&#125; 非springboot项目 依赖12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-mongodb&lt;/artifactId&gt; &lt;version&gt;1.3.5.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mongodb&lt;/groupId&gt; &lt;artifactId&gt;mongo-java-driver&lt;/artifactId&gt; &lt;version&gt;2.14.2&lt;/version&gt;&lt;/dependency&gt; xml配置1234567891011121314151617181920212223242526&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:mongo=\"http://www.springframework.org/schema/data/mongo\" xmlns=\"http://www.springframework.org/schema/beans\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.1.xsd http://www.springframework.org/schema/data/mongo http://www.springframework.org/schema/data/mongo/spring-mongo.xsd\"&gt; &lt;mongo:mongo-client id=\"mongoClient\" host=\"127.0.0.1\" port=\"27017\"&gt; &lt;mongo:client-options connections-per-host=\"8\" threads-allowed-to-block-for-connection-multiplier=\"4\" connect-timeout=\"1000\" max-wait-time=\"1500\" socket-keep-alive=\"true\" socket-timeout=\"1500\" /&gt; &lt;/mongo:mongo-client&gt; &lt;mongo:db-factory id=\"mongoDbFactory\" dbname=\"myMongoDB\" mongo-ref=\"mongoClient\"/&gt; &lt;mongo:template id=\"mongoTemplate\" db-factory-ref=\"mongoDbFactory\" write-concern=\"NORMAL\"/&gt; &lt;mongo:repositories base-package=\"com.xxx.core.modules.*.repository\"/&gt;&lt;/beans&gt; 创建存储的User实体123456789101112131415161718192021 public class User &#123; @Id private Long id; private String username; private Integer age; public User(Long id, String username, Integer age) &#123; this.id = id; this.username = username; this.age = age; &#125; @Override public String toString() &#123; return \"User&#123;\" + \"id=\" + id + \", username='\" + username + '\\'' + \", age=\" + age + '&#125;'; &#125;&#125; 实现User的数据访问对象123public interface UserRepository extends MongoRepository&lt;User, Long&gt; &#123; User findByUsername(String username);&#125; 测试 相关实体类注解的解释 123456789101112131415@Id - 文档的唯一标识，在mongodb中为ObjectId，它是唯一的，通过时间戳+机器标识+进程ID+自增计数器（确保同一秒内产生的Id不会冲突）构成。@Document - 把一个java类声明为mongodb的文档，可以通过collection参数指定这个类对应的文档。@Document(collection=\"mongodb\") mongodb对应表@DBRef - 声明类似于关系数据库的关联关系。ps：暂不支持级联的保存功能，当你在本实例中修改了DERef对象里面的值时，单独保存本实例并不能保存DERef引用的对象，它要另外保存，如下面例子的Person和Account。@Indexed - 声明该字段需要索引，建索引可以大大的提高查询效率。@CompoundIndex - 复合索引的声明，建复合索引可以有效地提高多字段的查询效率。@GeoSpatialIndexed - 声明该字段为地理信息的索引。@Transient - 映射忽略的字段，该字段不会保存到mongodb。@PersistenceConstructor - 声明构造函数，作用是把从数据库取出的数据实例化为对象。该构造函数传入的值为从DBObject中取出的数据","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"},{"name":"nosql","slug":"nosql","permalink":"https://www.qiudx.top/tags/nosql/"}]},{"title":"HashMap源码解析和安全性问题","date":"2017-11-18T12:00:51.000Z","path":"2017/11/18/HashMap源码解析和安全性问题/","text":"概要 hashmap的实现 hashmap为什么是线程不安全的 JDK8 如何修复多线程扩容Bug hashmap的实现hashmap的组成 数组+链表+红黑树 HashMap的实现使用了一个数组，每个数组项里面有一个链表的方式来实现，因为HashMap使用key的hashCode来寻找存储位置，不同的key可能具有相同的hashCode，这时候就出现哈希冲突了，也叫做哈希碰撞，为了解决哈希冲突，有开放地址方法，以及链地址方法。HashMap的实现上选取了链地址方法，也就是将哈希值一样的entry保存在同一个数组项里面，可以把一个数组项当做一个桶，桶里面装的entry的key的hashCode是一样的。在Java8中当一个桶entry数量超过8时,就会转化为红黑树 上面的图片展示了我们的描述，其中有一个非常重要的数据结构Node&lt;K,V&gt;，这就是实际保存我们的key-value对的数据结构，下面是这个数据结构的主要内容： 1234567891011121314//单链表结构 static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; &#125; 源码解析HashMap的put方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K, V&gt;[] tab; Node&lt;K, V&gt; p; int n, i; // table未初始化或者长度为0，进行扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // (n - 1) &amp; hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中) if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 桶中已经存在元素 else &#123; Node&lt;K, V&gt; e; K k; // 比较桶中第一个元素(数组中的结点)的hash值相等，key相等 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 将第一个元素赋值给e，用e来记录 e = p; // hash值不相等，即key不相等；为红黑树结点 else if (p instanceof TreeNode) // 放入树中 e = ((TreeNode&lt;K, V&gt;) p).putTreeVal(this, tab, hash, key, value); // 为链表结点 else &#123; // 在链表最末插入结点 for (int binCount = 0; ; ++binCount) &#123; // 到达链表的尾部 if ((e = p.next) == null) &#123; // 在尾部插入新结点 p.next = newNode(hash, key, value, null); // 结点数量达到阈值，转化为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); // 跳出循环 break; &#125; // 判断链表中结点的key值与插入的元素的key值是否相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 相等，跳出循环 break; // 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表 p = e; &#125; &#125; // 表示在桶中找到key值、hash值与插入元素相等的结点 if (e != null) &#123; // 记录e的value V oldValue = e.value; // onlyIfAbsent为false或者旧值为null if (!onlyIfAbsent || oldValue == null) //用新值替换旧值 e.value = value; // 访问后回调 afterNodeAccess(e); // 返回旧值 return oldValue; &#125; &#125; // 结构性修改 ++modCount; // 实际大小大于阈值则扩容 if (++size &gt; threshold) resize(); // 插入后回调 afterNodeInsertion(evict); return null;&#125; 流程图如下 resize机制HashMap的扩容机制就是重新申请一个容量是当前的2倍的桶数组，然后将原先的记录逐个重新映射到新的桶里面，然后将原先的桶逐个置为null使得引用失效。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899final Node&lt;K, V&gt;[] resize() &#123; //获得原来的table数组 Node&lt;K, V&gt;[] oldTab = table; //原table数组的容量 int oldCap = (oldTab == null) ? 0 : oldTab.length; //原扩容阈值 int oldThr = threshold; //定义新容量与阈值 int newCap, newThr = 0; //如果原容量&gt;0 if (oldCap &gt; 0) &#123; //如果原容量已经达到最大了1&lt;&lt;30，则不进行扩容，只调整阈值为最大，随其碰撞了 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //如果没达到最大，则变为原来容量的2倍 //其实这句可分解 //newCap = oldCap &lt;&lt; 1 //如果扩容后的容量小于最大容量才会将阈值变为原来的2倍 //else if (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // newThr = oldThr &lt;&lt; 1; // double threshold else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //如果oldCap = 0，oldThr &gt; 0 这是适用于不同的构造函数的 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; //默认构造器的处理 else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int) (DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //如果扩容后的容量大于最大容量了1&lt;&lt;30 if (newThr == 0) &#123; float ft = (float) newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float) MAXIMUM_CAPACITY ? (int) ft : Integer.MAX_VALUE); &#125; //设置为新的值 threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\", \"unchecked\"&#125;) Node&lt;K, V&gt;[] newTab = (Node&lt;K, V&gt;[]) new Node[newCap]; table = newTab; //完成rehash if (oldTab != null) &#123; //遍历原数组的每一个位置 所以rehash过程的是很耗费时间的 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K, V&gt; e; //e = oldTab[j]) if ((e = oldTab[j]) != null) &#123; //将原位置设为null oldTab[j] = null; //如果没有碰撞，也就是只有这一个元素，直接定位设置到新数组的位置 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //如果当前节点是TreeNode类型，说明已经树化了，红黑树的rehash过程 else if (e instanceof TreeNode) ((TreeNode&lt;K, V&gt;) e).split(this, newTab, j, oldCap); //表明当前节点冲突是链表存储的，完成rehash //注意：这是1.8的优化点，这也是容量声明为2的次幂的另一个应用 else &#123; // preserve order //rehash后将桶中的值重新分配 Node&lt;K, V&gt; loHead = null, loTail = null;//记录低位链表头尾位置 Node&lt;K, V&gt; hiHead = null, hiTail = null;//记录高位链表头尾位置 Node&lt;K, V&gt; next;//记录当前链表元素在原来链表中的下一个元素，便于下次循环使用 //遍历哈希桶的链表，拆分成高位和低位链表(为了更好的理解扩容,实际上只有一条单向链表) do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; //新增的有效哈希位为0，即当前元素扩容后分配到 低位链表 其实位置相比以前没变 if (loTail == null) //低位链表尚未初始化 loHead = e; //设置低位链表头部 else loTail.next = e; //低位链表尾部增加当前元素，以保持原链表顺序 loTail = e; //更新低位链表的尾部 &#125; else &#123; //新增的有效哈希位为1，即当前元素扩容后分配到 高位链表 扩容后的位置 if (hiTail == null) //高低位链表尚未初始化 hiHead = e; //设置高位链表头部 else hiTail.next = e; //高位链表尾部增加当前元素，以保持原链表顺序 hiTail = e; //更新高位链表的尾部 &#125; &#125; while ((e = next) != null); //更新两个链表到哈希表中 if (loTail != null) &#123; //扩容后低位链表不为空，需要处理 loTail.next = null; //低位链表设置尾部结束 newTab[j] = loHead; //哈希桶设置链表入口 &#125; if (hiTail != null) &#123; //扩容后高位链表不为空，需要处理 hiTail.next = null; //高位链表设置尾部结束 newTab[j + oldCap] = hiHead; //哈希桶设置链表入口 &#125; &#125; &#125; &#125; &#125; return newTab;&#125; get方法（返回指定键所映射的值）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public V get(Object key) &#123; Node&lt;K, V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; final Node&lt;K, V&gt; getNode(int hash, Object key) &#123; Node&lt;K, V&gt;[] tab; Node&lt;K, V&gt; first, e; int n; K k; // table已经初始化，长度大于0，根据hash寻找table中的项也不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 桶中第一项(数组元素)相等 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 桶中不止一个结点 if ((e = first.next) != null) &#123; // 为红黑树结点 if (first instanceof TreeNode) // 在红黑树中查找 return ((TreeNode&lt;K, V&gt;) first).getTreeNode(hash, key); // 否则，在链表中查找 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; final TreeNode&lt;K, V&gt; getTreeNode(int h, Object k) &#123; //找到红黑树的根节点并遍历红黑树 return ((parent != null) ? root() : this).find(h, k, null); &#125; //找到从根p开始的节点和给定的散列和键。kc参数在第一次使用比较键时缓存了comparableClassFor。 final TreeNode&lt;K, V&gt; find(int h, Object k, Class&lt;?&gt; kc) &#123; TreeNode&lt;K, V&gt; p = this; do &#123; int ph, dir; K pk; TreeNode&lt;K, V&gt; pl = p.left, pr = p.right, q; if ((ph = p.hash) &gt; h) p = pl; else if (ph &lt; h) p = pr; else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; else if (pl == null) p = pr; else if (pr == null) p = pl; else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; (dir = compareComparables(kc, k, pk)) != 0) p = (dir &lt; 0) ? pl : pr; else if ((q = pr.find(h, k, kc)) != null) return q; else p = pl; &#125; while (p != null); return null; &#125; treeifyBin方法（将容器中的node变为treeNode）1234567891011121314151617181920212223242526272829303132final void treeifyBin(Node&lt;K, V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K, V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); //Node e=tab[该hash对应的角标]，e就是这个角标下的第一个元素。 else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K, V&gt; hd = null, tl = null; do &#123; //replacementTreeNode == new TreeNode(),就是包装了一个TreeNode对象 TreeNode&lt;K, V&gt; p = replacementTreeNode(e, null); if (tl == null) //遍历链表上的第一个元素的时候，t1==null，将p赋值给hd //也就是先记录一下，方便后面的元素记录pre，next hd = p; else &#123; //现在p是个tree了，pre记录上一个元素 p.prev = tl; //顺便把自己的引用在上一个元素上做记录 tl.next = p; &#125; //将当前操作的元素的引用传递给t1 tl = p; //遍历整个链表，直到没有元素。 &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) //遍历完了，再执行hd.treeify方法 //hd=p是在t1==null时执行，也就是只有在第一个元素的时候执行了一次 //所以hd代表的是这个树的根。 hd.treeify(tab); &#125;&#125; remove方法（移除指定键的映射关系）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public V remove(Object key) &#123; Node&lt;K, V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;final Node&lt;K, V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K, V&gt;[] tab; Node&lt;K, V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K, V&gt; node = null, e; K k; V v; // 直接命中 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; // 红黑树中查找 if (p instanceof TreeNode) node = ((TreeNode&lt;K, V&gt;) p).getTreeNode(hash, key); else &#123; // 链表中查找 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; // 命中后删除 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K, V&gt;) node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; // 链表首元素删除 else p.next = node.next; //多元素链表节点删除 ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125; hashmap为什么是线程不安全的 多线程环境put的时候导致的数据不一致问题 这个问题比较好想象，比如有两个线程A和B，首先A希望插入一个key-value对到HashMap中，首先计算记录所要落到的桶的索引坐标，然后获取到该桶里面的链表头结点，此时线程A的时间片用完了，而此时线程B被调度得以执行，和线程A一样执行，只不过线程B成功将记录插到了桶里面，假设线程A插入的记录计算出来的桶索引和线程B要插入的记录计算出来的桶索引是一样的，那么当线程B成功插入之后，线程A再次被调度运行时，它依然持有过期的链表头但是它对此一无所知，以至于它认为它应该这样做，如此一来就覆盖了线程B插入的记录，这样线程B插入的记录就凭空消失了，造成了数据不一致的行为。下面是一个简单的例子 1234567891011121314151617181920212223242526272829303132public class Test &#123; private static final Map&lt;String, String&gt; hashMap = new HashMap&lt;&gt;(); public static void main(String[] args) &#123; Thread t1 = new Thread(() -&gt; &#123; for (int i = 0; i &lt; 25; i++) &#123; hashMap.put(i + \"\", i + \"\"); &#125; &#125;); Thread t2 = new Thread(() -&gt; &#123; for (int i = 25; i &lt; 50; i++) &#123; hashMap.put(i + \"\", i + \"\"); &#125; &#125;); t1.start(); t2.start(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; for (int i = 0; i &lt; 50; i++) &#123; System.out.println(i + \"/\" + hashMap.get(i + \"\")); &#125; &#125;&#125; 结果如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849500/01/12/23/34/45/null6/67/78/89/910/1011/null12/1213/1314/1415/null16/1617/1718/1819/1920/2021/2122/2223/2324/2425/2526/null27/2728/2829/2930/3031/3132/3233/null34/3435/3536/3637/3738/null39/3940/4041/4142/4243/4344/4445/4546/4647/4748/4849/49 JDK8 如何修复多线程扩容Bug源码分析上面有 JDK8 中Node&lt;K,V&gt;[] resize()每次扩容哈希表大小都增倍特性，每次扩容，一个哈希桶里的元素在扩容后的位置，只会是原位置，或者原位置+原哈希表。 扩容后，原来哈希桶的链表被拆分为两个，两个链表中的元素都能继续维持原有的顺序。这样就算在多线程环境下同时扩容，一个线程A读取链表状态后停止工作，另一个线程B对同一链表的前几个元素进行扩容分成两个链表，此时线程A恢复工作，由于线程B对链表元素的顺序没有发生变化，所以线程A恢复工作后只是重复了拆分链表的工作，而不会因为链表已被改变顺序而导致环的生成，因此不会发生死循环的问题。 也就是说 JDK8 的HashMap扩容方法不但效率提升了（根据哈希值特点拆分链表，红黑树），而且还维持了扩容前后的链表顺序，从而解决了多线程扩容使链表产生环，导致死循环的问题。","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"},{"name":"面试","slug":"面试","permalink":"https://www.qiudx.top/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"spring boot freemarker全局属性","date":"2017-11-17T03:32:46.000Z","path":"2017/11/17/spring-boot-freemarker全局属性/","text":"在spring boot中配置freemarker的全局属性123456789101112@Configurationpublic class FreemarkerConfiguration extends FreeMarkerAutoConfiguration.FreeMarkerWebConfiguration &#123; @Override public FreeMarkerConfigurer freeMarkerConfigurer() &#123; FreeMarkerConfigurer configurer = super.freeMarkerConfigurer(); Map&lt;String, Object&gt; sharedVariables = new HashMap&lt;&gt;(); sharedVariables.put(\"BASE_URL\", \"/admin\"); configurer.setFreemarkerVariables(sharedVariables); return configurer; &#125;&#125;","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://www.qiudx.top/tags/spring-boot/"}]},{"title":"Docker常用命令","date":"2017-11-16T07:45:33.000Z","path":"2017/11/16/Docker常用命令/","text":"概要 docker简介 容器相关 操作Image Docker简介Docker的应用场景 Web 应用的自动化打包和发布。 自动化测试和持续集成、发布。 在服务型环境中部署和调整数据库或其他的后台应用。 从头编译或者扩展现有的OpenShift或Cloud Foundry平台来搭建自己的PaaS环境。 Docker 的优点 简化程序 节省开支 Docker安装使用 yum 安装（CentOS 7下） 安装dockers 12yum -y install dockerservice docker start 配置加速器 在Daocloud上注册账户,就可以在加速器页面领取一个docker加速器的key 配置(自己查文档) 容器相关启动容器1234567docker run -i -t &lt;image_name/continar_id&gt; /bin/bash-i：表示以“交互模式”运行容器-t：表示容器启动后会进入其命令行-d：表示以守护模式执行/bin/bash脚本，此时 Tomcat 控制台不会出现在输出终端上。–name：表示容器名称，用一个有意义的名称命名即可。-p：表示宿主机与容器的端口映射-v：表示需要将本地哪个目录挂载到容器中 操作容器 进入正在运行的容器 1docker attach &lt;id、container_name&gt; 后台容器执行命令 1docker exec &lt;id、container_name&gt; 查看容器日志 查看容器日志1234docker logs &lt;id/container_name&gt;-t 时间戳-tail 显示多少行-f 实时滚动 查看容器信息 查看容器123docker ps : 查询正在运行的容器-a:查看所有容器-l:最后一次运行的容器 显示一个运行的容器里面的进程信息1docker top Name/ID 在容器中安装新的程序1docker run image_name apt-get install -y app_name 删除容器 删除单个容器 1docker rm Name/ID 删除全部容器 1docker rm `docker ps -a -q` 停止、启动、杀死、重启一个容器 1234docker stop Name/ID docker start Name/ID docker kill Name/ID docker restart name/ID 操作Image 列出镜像1234sudo docker images-a, –all=false Show all images;no-trunc=false Don’t truncate output;-q, –quiet=false Only show numeric IDs 下载image1docker search image_name 删除一个或者多个镜像;123docker rmi image_name -f, –force=false Force;–no-prune=false Do not delete untagged parents 显示一个镜像的历史;1docker history image_name 发布docker镜像1docker push new_image_name 拉取docker镜像1docker pull image_name","tags":[{"name":"linux","slug":"linux","permalink":"https://www.qiudx.top/tags/linux/"},{"name":"docker","slug":"docker","permalink":"https://www.qiudx.top/tags/docker/"}]},{"title":"分布式事务解决方案下","date":"2017-11-15T01:38:24.000Z","path":"2017/11/15/分布式事务解决方案下/","text":"概要 柔性事务解决方案概述 可靠消息最终一致性解决方案 最大努力通知性解决方案 TCC 幂等性 柔性事务解决方案概述什么是柔性事务个人理解: 柔性事务可以说是伪事务,柔性事务其实是根据不同的业务场景在业务层使用不同的方法(2pc,事后补偿,消息队列)实现最终一致性 可靠消息最终一致性解决方案理解: 采取事件机制和消息队列实现分布式事务,来确保消息的最终一致性 最大努力通知性解决方案理解: 业务主动方完成业务后向业务被动方发送业务通知,允许消息发送失败,当消息发送失败时会按规制重发N次,如果N次后还未收到业务被动方回复则不在发送消息,业务主动方会提供可查询接口供业务被动方查询 行业示例: 银行通知,商户通知 TCC理解: TCC实际是将一个整体事务拆分为一个个小事务(本地事务),每个事务见互不干扰 Try：预留业务资源 Confirm：确认执行业务操作 Cancel：取消执行业务操作 一个完整的TCC事务参与方包括三部分 主业务服务：主业务服务为整个业务活动的发起方。 从业务服务：从业务服务负责提供TCC业务操作，是整个业务活动的操作方。从业务服务必须实现Try、Confirm和Cancel三个接口，供主业务服务调用。 业务活动管理器(框架内部)：业务活动管理器管理控制整个业务活动，包括记录维护TCC全局事务的事务状态和每个从业务服务的子事务状态，并在业务活动提交时确认所有的TCC型操作的confirm操作，在业务活动取消时调用所有TCC型操作的cancel操作。 TCC的优点和限制 TCC事务的优点: 解决了跨应用业务操作的原子性问题，在诸如组合支付、账务拆分场景非常实用。 TCC实际上把数据库层的二阶段提交上提到了应用层来实现，对于数据库来说是一阶段提交，规避了数据库层的2PC性能低下问题。 TCC事务的缺点 TCC的Try、Confirm和Cancel操作功能需业务提供，开发成本高。 案例理解(三个不同分库的帐户A、B、C，A和B一起向C转帐共80元) Try：尝试执行业务。完成所有业务检查(一致性)：检查A、B、C的帐户状态是否正常，帐户A的余额是否不少于30元，帐户B的余额是否不少于50元。预留必须业务资源(准隔离性)：帐户A的冻结金额增加30元，帐户B的冻结金额增加50元，这样就保证不会出现其他并发进程扣减了这两个帐户的余额而导致在后续的真正转帐操作过程中，帐户A和B的可用余额不够的情况。 Confirm：确认执行业务。真正执行业务：如果Try阶段帐户A、B、C状态正常，且帐户A、B余额够用，则执行帐户A给账户C转账30元、帐户B给账户C转账50元的转帐操作。不做任何业务检查：这时已经不需要做业务检查，Try阶段已经完成了业务检查。只使用Try阶段预留的业务资源：只需要使用Try阶段帐户A和帐户B冻结的金额即可。 Cancel：取消执行业务释放Try阶段预留的业务资源：如果Try阶段部分成功，比如帐户A的余额够用，且冻结相应金额成功，帐户B的余额不够而冻结失败，则需要对帐户A做Cancel操作，将帐户A被冻结的金额解冻掉。 幂等性 简单的说, 业务操作支持重试, 不会产生不利影响. 常见的实现方式: 为消息额外增加唯一ID.根据业务状态判断","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"},{"name":"分布式","slug":"分布式","permalink":"https://www.qiudx.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"分布式事务解决方案上","date":"2017-11-14T05:38:24.000Z","path":"2017/11/14/分布式事务解决方案上/","text":"概要 事务 BSAE理论 CAP理论 全局事务介绍 事务 什么是事务事务是应用程序中一系列严密的操作，所有操作必须成功完成，否则在每个操作中所做的所有更改都会被撤消 事务的特性 一致性 事务在完成时，必须使所有的数据都保持一致状态。在相关数据库中，所有规则都必须应用于事务的修改，以保持所有数据的完整性。事务结束时，所有的内部数据结构都必须是正确的。 原子性 事务必须是原子工作单元。对于其数据修改，要么全都执行，要么全都不执行。 持久性 事务完成之后，它对于系统的影响是永久性的。该修改即使出现系统故障也将一直保持。 隔离性 由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。事务识别数据时数据所处的状态，或者是另一个并发事务修改它之前的状态，或者是第二个事务修改它之后的状态，事务不会识别中间状态的数据。这称为可串行性，因为它能够重新装载起始数据，并且重播一系列事务，以使数据结束时的状态与原始事务执行的状态相同。 运行模式 自动提交事务：每条单独的语句都是一个事务。 显式事务：每个事务均以BEGIN TRANSACTION语句显式开始，以COMMIT或ROLLBACK语句显式结束。 隐性事务：在上个事务完成时新事务隐式启动，但每个事务仍以COMMIT或ROLLBACK语句显式完成。 BASE理论BA基本业务可用性支持分区失败(允许部分服务异常) 响应时间上的损失。正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障，查询结果的响应时间增加了1~2秒 系统功能上的损失。正常情况下，在一个电子商务网站上进行购物的时候，消费者几乎能够顺利完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面 S柔性状态(软状态)软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时 E: 最终一致性 最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 核心思想: 即使无法做到强一致性，那么每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性 原子性和持久性必须保证,只有适当降低一致性和隔离性 CAP理论C: 一致性 all nodes see the same data at the same time A: 原子性 Reads and writes always succeed P:分区容错性the system continues to operate despite arbitrary message loss or failure of part of the system 选择 说明 CA 降低分区容错性,加强一致性和可用性,其实就是传统的单机数据库的选择 AP 降低一致性(这里说的一致性是指强一致性),加强分区容错性和可用性,现在很多分布式系统都是这么设计的,例如eureka CP 降低可用性,追求一致性和分容错性,基本不会选择,如果网络出现问题会导致系统不可用,例如zookeeper 分布式系统中,分区容错性是一个最基本的要求。因为分布式系统中组件必须被部署在不同的节点上,因而服务间必须跨网络调用。对于分布式系统而言网络问题是必然会出现的,因此分区容错就成了每一个分布式系统中绕不去的坎,往往架构师们都在一致性和可用性中寻求平衡点 常见的分布式解决方案刚性事务解决方案 标准的分布式解决方案(全局事务) 优缺点 分析 优点 严格的ACID 缺点 1. 效率非常的低,在全局事务方式下,全局事务管理器TM通过XA接口使用两阶段提交协议(2pc)与资源层(数据 库)交互时,数据被锁定的时间跨越了整个事务,直到全局事务结束 2. 业务规模越来越大时,2pc局限性越明显,系统可伸缩性会很差 3. XA协议系统开销大,只有支持XA协议的资源才能参与分布式事务 分布式系统中很少采取这种方案,刚性事务力度大,时间长,效率低.下节将介绍柔性事务解决方案","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"},{"name":"分布式","slug":"分布式","permalink":"https://www.qiudx.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"数组","date":"2017-11-13T17:34:53.000Z","path":"2017/11/14/数组/","text":"数组概要 数组是一种引用数据类型 数组是一组数据的集合,是一种容器 数组中的元素类型可以是基本类型也可是引用数据类型,但同一个数组中只能有一种类型 数组的长度在数组创建的时候就确定了,无法在创建后再次修改 数组是由下标的,0表示第一个元素 数组的创建 一维数组 基本类型数组 123456//动态初始化int[] intArr = new int[3]; //数组创建int[0]=1; //通过下标赋值//静态初始化int[] a = &#123;1, 2, 3, 4&#125;; 引用类型数组 123456//动态初始化String[] stringArr = new String[3]; //数组创建stringArr[0] = new String(); //通过下标赋值//静态初始化String[] aa = &#123;\"a\", \"as\", \"asd\"&#125;; 二维数组 当数组元素的类型是数组时就成了多维数组，二维数组的声明格式如下： 数组元素的数据类型[][] 变量名； 数组元素的数据类型 变量名[][]； 数组的排序冒泡排序假设有5个数字3，1，6，2，5在一个int数组中，要求按从小到大排序输出如何采用冒泡排序算法呢？冒泡排序的算法是这样的，首先从数组的最左边开始，取出第0号位置（左边）的数据和第1号位置（右边）的数据，如果左边的数据大于右边的数据，则进行交换，否而不进行交换。接下来右移一个位置，取出第1个位置的数据和第2个位置的数据，进行比较，如果左边的数据大于右边的数据，则进行交换，否而不进行交换。沿着这个算法一直排序下去，最大的数就会冒出水面，这就是冒泡排序。 1234567891011121314151617public class ArraySortTest01 &#123; public static void main(String[] args) &#123; int[] data = &#123;3, 1, 6, 2, 5&#125;; for (int i = data.length - 1; i &gt; 0; i--) &#123; for (int j = 0; j &lt; i; j++) &#123; if (data[j] &gt; data[j + 1]) &#123; int temp = data[j]; data[j] = data[j + 1]; data[j + 1] = temp; &#125; &#125; &#125; for (int aData : data) &#123; System.out.println(aData); &#125; &#125;&#125; 选择排序选择排序对冒泡排序进行了改进，使交换次数减少，但比较次数仍然没有减少。假设有5个数字3，1，6，2，5在一个int数组中，要求按从小到大排序输出采用选择排序，选择排序是这样的，先从左端开始，找到下标为0的元素，然后和后面的元素依次比较，如果找到了比下标0小的元素，那么再使用此元素，再接着依次比较，直到比较完成所有的元素，最后把最小的和第0个位置交换。 123456789101112131415161718192021public class ArraySortTest02 &#123; public static void main(String[] args) &#123; int[] data = &#123;3, 1, 6, 2, 5&#125;; for (int i = data.length - 1; i &gt; 0; i--) &#123; int max = 0; for (int j = 0; j &lt; i; j++) &#123; if (data[max] &lt; data[j + 1]) &#123; max = j + 1; &#125; &#125; if (max != i) &#123; int temp = data[i]; data[i] = data[max]; data[max] = temp; &#125; &#125; for (int aData : data) &#123; System.out.println(aData); &#125; &#125;&#125;","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"},{"name":"面试","slug":"面试","permalink":"https://www.qiudx.top/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"JavaSE","date":"2017-11-04T19:47:53.000Z","path":"2017/11/05/JavaSE/","text":"目标 来到新公司已一年有余,学了很多新的技术,学的越多基础的知识忘得也是越多,所以我觉得应该将以往学的东西复习一遍 将以往没有深入学的IO,反射深入学习 为下家公司跳槽作知识储备 方向","tags":[{"name":"java","slug":"java","permalink":"https://www.qiudx.top/tags/java/"},{"name":"杂记","slug":"杂记","permalink":"https://www.qiudx.top/tags/%E6%9D%82%E8%AE%B0/"}]},{"title":"我的博客","date":"2017-11-04T15:34:36.000Z","path":"2017/11/04/我的博客/","text":"心得： 第一次写博客有点激动，昨天利用了一天时间搭了自己的独立博客 希望通过写博客来练习写Markdown 把自己学到记录下来方便日后查阅 博客的搭建过程http://pupiles.com/How-to-make-a-blog.html","tags":[{"name":"杂记","slug":"杂记","permalink":"https://www.qiudx.top/tags/%E6%9D%82%E8%AE%B0/"}]}]